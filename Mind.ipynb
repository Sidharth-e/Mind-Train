{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0123ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q transformers trl peft bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db40d226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Could not import module 'validate_bnb_backend_availability'. Are this object's requirements defined correctly?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2317\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2316\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2317\u001b[39m     module = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2318\u001b[39m     value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2347\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2347\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2345\u001b[39m, in \u001b[36m_LazyModule._get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2344\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2345\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\importlib\\__init__.py:88\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     87\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1398\u001b[39m, in \u001b[36m_gcd_import\u001b[39m\u001b[34m(name, package, level)\u001b[39m\n\u001b[32m   1397\u001b[39m     name = _resolve_name(name, package, level)\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_and_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1371\u001b[39m, in \u001b[36m_find_and_load\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m _NEEDS_LOADING:\n\u001b[32m-> \u001b[39m\u001b[32m1371\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_find_and_load_unlocked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimport_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;66;03m# Optimization: only call _bootstrap._lock_unlock_module() if\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;66;03m# module.__spec__._initializing is True.\u001b[39;00m\n\u001b[32m   1375\u001b[39m \u001b[38;5;66;03m# NOTE: because of this, initializing must be set *before*\u001b[39;00m\n\u001b[32m   1376\u001b[39m \u001b[38;5;66;03m# putting the new module in sys.modules.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1342\u001b[39m, in \u001b[36m_find_and_load_unlocked\u001b[39m\u001b[34m(name, import_)\u001b[39m\n\u001b[32m   1341\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     module = \u001b[43m_load_unlocked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:938\u001b[39m, in \u001b[36m_load_unlocked\u001b[39m\u001b[34m(spec)\u001b[39m\n\u001b[32m    936\u001b[39m         \u001b[38;5;66;03m# A namespace package so do nothing.\u001b[39;00m\n\u001b[32m    937\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m938\u001b[39m         \u001b[43mspec\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexec_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap_external>:762\u001b[39m, in \u001b[36m_LoaderBasics.exec_module\u001b[39m\u001b[34m(self, module)\u001b[39m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mcannot load module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m when \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    761\u001b[39m                       \u001b[33m'\u001b[39m\u001b[33mget_code() returns None\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m762\u001b[39m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_with_frames_removed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__dict__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:491\u001b[39m, in \u001b[36m_call_with_frames_removed\u001b[39m\u001b[34m(f, *args, **kwds)\u001b[39m\n\u001b[32m    484\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"remove_importlib_frames in import.c will always remove sequences\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[33;03mof importlib frames that end with a call to this function\u001b[39;00m\n\u001b[32m    486\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    489\u001b[39m \u001b[33;03mmodule code)\u001b[39;00m\n\u001b[32m    490\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:20\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_bitsandbytes_available():\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbitsandbytes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbnb\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\bitsandbytes\\__init__.py:19\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpu\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops \u001b[38;5;28;01mas\u001b[39;00m cpu_ops\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdefault\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops \u001b[38;5;28;01mas\u001b[39;00m default_ops\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m modules\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\bitsandbytes\\backends\\default\\ops.py:324\u001b[39m\n\u001b[32m    314\u001b[39m name2optimizer_id = {\n\u001b[32m    315\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmomentum\u001b[39m\u001b[33m\"\u001b[39m: MOMENTUM,\n\u001b[32m    316\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mrmsprop\u001b[39m\u001b[33m\"\u001b[39m: RMSPROP,\n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mademamix\u001b[39m\u001b[33m\"\u001b[39m: ADEMAMIX,\n\u001b[32m    321\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m \u001b[38;5;129;43m@torch\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m_optimizer_precondition_32bit\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mg\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mp\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate1\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate2\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43munorm_vec\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgnorm_scale\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_id\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[38;5;250;43m    \u001b[39;49m\u001b[33;43;03m\"\"\"Preprocessing optimizer, computing update norm\"\"\"\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\torch\\__init__.py:2590\u001b[39m, in \u001b[36mcompile\u001b[39m\u001b[34m(model, fullgraph, dynamic, backend, mode, options, disable)\u001b[39m\n\u001b[32m   2589\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sys.version_info >= (\u001b[32m3\u001b[39m, \u001b[32m14\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m2590\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mtorch.compile is not supported on Python 3.14+\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2591\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m sysconfig.get_config_var(\u001b[33m\"\u001b[39m\u001b[33mPy_GIL_DISABLED\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sys.version_info < (\n\u001b[32m   2592\u001b[39m     \u001b[32m3\u001b[39m,\n\u001b[32m   2593\u001b[39m     \u001b[32m13\u001b[39m,\n\u001b[32m   2594\u001b[39m     \u001b[32m3\u001b[39m,\n\u001b[32m   2595\u001b[39m ):\n",
      "\u001b[31mRuntimeError\u001b[39m: torch.compile is not supported on Python 3.14+",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 130\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Quantization config (Makes the model smaller to fit in memory)\u001b[39;00m\n\u001b[32m    124\u001b[39m bnb_config = BitsAndBytesConfig(\n\u001b[32m    125\u001b[39m     load_in_4bit=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    126\u001b[39m     bnb_4bit_quant_type=\u001b[33m\"\u001b[39m\u001b[33mnf4\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    127\u001b[39m     bnb_4bit_compute_dtype=torch.float16,\n\u001b[32m    128\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    134\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001b[32m    136\u001b[39m tokenizer.pad_token = tokenizer.eos_token \u001b[38;5;66;03m# Fix for padding issues\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:604\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    602\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    603\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    608\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    609\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    610\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4881\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4872\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transformers_explicit_filename.endswith(\n\u001b[32m   4873\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m.safetensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4874\u001b[39m     ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m transformers_explicit_filename.endswith(\u001b[33m\"\u001b[39m\u001b[33m.safetensors.index.json\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   4875\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4876\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe transformers file in the config seems to be incorrect: it is neither a safetensors file \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4877\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m(*.safetensors) nor a safetensors index file (*.safetensors.index.json): \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4878\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtransformers_explicit_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   4879\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m4881\u001b[39m hf_quantizer, config, dtype, device_map = \u001b[43mget_hf_quantizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_agent\u001b[49m\n\u001b[32m   4883\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4885\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4886\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4887\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou cannot combine Quantization and loading a model from a GGUF file, try again by making sure you did not passed a `quantization_config` or that you did not load a quantized model from the Hub.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4888\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\transformers\\quantizers\\auto.py:319\u001b[39m, in \u001b[36mget_hf_quantizer\u001b[39m\u001b[34m(config, quantization_config, dtype, from_tf, from_flax, device_map, weights_only, user_agent)\u001b[39m\n\u001b[32m    316\u001b[39m     hf_quantizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     \u001b[43mhf_quantizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     dtype = hf_quantizer.update_dtype(dtype)\n\u001b[32m    327\u001b[39m     device_map = hf_quantizer.update_device_map(device_map)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py:103\u001b[39m, in \u001b[36mBnb4BitHfQuantizer.validate_environment\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.cuda.is_available():\n\u001b[32m     98\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     99\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe installed version of bitsandbytes (<0.43.1) requires CUDA, but CUDA is not available. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou may need to install PyTorch with CUDA support or upgrade bitsandbytes to >=0.43.1.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mintegrations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_bnb_backend_availability\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_multi_backend_available\n\u001b[32m    106\u001b[39m bnb_multibackend_is_enabled = is_bitsandbytes_multi_backend_available()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sidha\\Desktop\\Projects\\Mind Train\\.venv\\Lib\\site-packages\\transformers\\utils\\import_utils.py:2320\u001b[39m, in \u001b[36m_LazyModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   2318\u001b[39m         value = \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m   2319\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m2320\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[32m   2321\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not import module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Are this object\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms requirements defined correctly?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2322\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._modules:\n\u001b[32m   2325\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: Could not import module 'validate_bnb_backend_availability'. Are this object's requirements defined correctly?"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# 1. YOUR DATA\n",
    "# Define your Q&A pairs here. The more you have, the better.\n",
    "data =[\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWho is Sidharth E?\\n<|assistant|>\\nSidharth E is a Full Stack Developer based in Kerala, India, with experience in building scalable web applications. He specializes in React, Node.js, cloud platforms (Azure/AWS), and AI integrations.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat is Sidharth's current job title?\\n<|assistant|>\\nHe is currently a Full Stack Developer at KellyOCG.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nHow many years of experience does Sidharth have?\\n<|assistant|>\\nSidharth has over 4 years of experience. He started his career in January 2020 at Tata Consultancy Services.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat are Sidharth's core frontend skills?\\n<|assistant|>\\nHis frontend expertise includes HTML5/CSS/JS, TypeScript, React, Next.js, SASS, and Tailwind CSS.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhich backend technologies does Sidharth use?\\n<|assistant|>\\nHe is proficient in Node.js, ExpressJS, Python, and FastAPI.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nDoes Sidharth have experience with Cloud platforms?\\n<|assistant|>\\nYes, he has extensive experience with Azure and AWS. He also uses tools like Jenkins, Nginx, Bicep, and Linux for DevOps and CI/CD pipelines.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat AI and Machine Learning technologies does he know?\\n<|assistant|>\\nSidharth works with Agentic AI, Langchain, HuggingFace, MCP, GenAI, OpenAI, Gemini, and Azure AI.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat database systems is he familiar with?\\n<|assistant|>\\nHe uses MongoDB and CosmosDB.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat development tools does Sidharth use?\\n<|assistant|>\\nHe utilizes Git, Postman, VS Code, Cursor, Windsurf, Antigravity, and Microsoft Office tools like Excel and PowerPoint.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nHow can I contact Sidharth E?\\n<|assistant|>\\nYou can email him at sidharthe38943@gmail.com or call him at +91 6238471816. His portfolio is available at https://sidharthe.dev.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nTell me about his work at KellyOCG.\\n<|assistant|>\\nAt KellyOCG (Aug 2024 – Present), Sidharth develops AI-powered browser extensions. Key projects include 'GRACE Sync' and 'Project GRACE 2.0', focusing on Azure, OpenAI, and Cosmos DB integrations.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat is GRACE Sync?\\n<|assistant|>\\nGRACE Sync is an AI-powered browser extension developed by Sidharth. It processes data from internal web apps, features an AI chatbot, and uses Azure Identity for security. It also includes telemetry via PowerBI and history management with Cosmos DB.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat features did he implement in Project GRACE 2.0?\\n<|assistant|>\\nFor GRACE 2.0, he integrated file uploads with Gemini, added OCR for images, implemented real-time web search via Perplexity API, ensured Veracode compliance, and added Role-Based Access Control (RBAC).\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat did Sidharth do at Poumki Digital LLP?\\n<|assistant|>\\nFrom April 2023 to June 2024, he worked as a Full Stack Developer. He built the 'Project Convergence' data analytics platform, the 'e-slide' presentation platform, and enhanced the 'Izycourse' platform.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nDescribe Project Convergence.\\n<|assistant|>\\nProject Convergence is a Data Analytics Platform built on the MERN stack. Sidharth implemented CI/CD with Jenkins on AWS, set up a rollback system, reduced storage costs with Nexus/S3, and automated MongoDB backups.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat is Project e-slide?\\n<|assistant|>\\nIt is a presentation sharing platform where Sidharth added multilingual support using React-i18next and implemented user safety features like banning capabilities. The tech stack included React, SASS, DynamoDB, and AWS Lambda.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat was Sidharth's role at TCS?\\n<|assistant|>\\nHe held two roles at TCS: Site Reliability Engineer (Jan 2020 – Mar 2021) and Full Stack Developer for Rapid Labs (Mar 2021 – Apr 2023).\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nDid Sidharth work on healthcare projects?\\n<|assistant|>\\nYes, at TCS Rapid Labs, he built AI/ML prototypes for healthcare, including an ulcer detection model with 92% precision and a ticket prediction model with 85% accuracy using Python and Flask.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat automation tools did he build as an SRE?\\n<|assistant|>\\nHe built a 'Core Analysis Tool' to reduce incident resolution time by 30%, an 'Akamai report generator' saving 200+ hours annually, and an 'Auto Delegation Tool' to validate data discrepancies.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat is Sidharth's educational background?\\n<|assistant|>\\nHe is currently pursuing a Master of Computer Applications (MCA) in AI/ML at Amritha Vishwa Vidyapeetham (since Oct 2025). He holds a Bachelor of Computer Applications (BCA) from VLB Janakiammal College of Arts and Science (2017–2020).\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nHas Sidharth received any awards?\\n<|assistant|>\\nYes, he received the 'Star of the Month' award at TCS for developing three automation tools that saved over 500 work hours annually.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat languages does Sidharth speak?\\n<|assistant|>\\nHe speaks Malayalam (Native), English (Professional Proficiency), Tamil (Conversational), and Hindi (Conversational).\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nDoes Sidharth know how to use Docker or Containers?\\n<|assistant|>\\nHis skills list includes Linux and CI/CD pipelines. While Docker isn't explicitly listed in the 'Tools' array, his experience with AWS EC2, Jenkins, and Nginx suggests familiarity with containerized environments.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nIs Sidharth familiar with secure coding practices?\\n<|assistant|>\\nYes, in Project GRACE 2.0, he achieved full Veracode compliance by fixing high-severity vulnerabilities and implemented RBAC (Role-Based Access Control) for security.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nDoes he have experience with Search APIs?\\n<|assistant|>\\nYes, he implemented real-time web search using the Perplexity API for Project GRACE 2.0.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat specific AI models has he integrated?\\n<|assistant|>\\nHe has integrated OpenAI models and Google Gemini. He also lists 'HuggingFace' and 'Langchain' in his AI/ML skills.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat is the 'Antigravity' tool mentioned in his skills?\\n<|assistant|>\\nAntigravity is listed under his 'Tools' category, likely referring to an AI-assisted coding or development tool he utilizes.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nCan Sidharth build browser extensions?\\n<|assistant|>\\nYes, he built 'GRACE Sync,' a complex browser extension that reinjects data into web apps and manages chat history.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat cloud infrastructure as code (IaC) tools does he use?\\n<|assistant|>\\nHe uses Bicep, specifically mentioned in the tech stack for Project GRACE 2.0 on Azure.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nDoes Sidharth have experience with real-time communication?\\n<|assistant|>\\nYes, he implemented real-time user interactions using Socket.IO for Project Convergence and lists WebSockets under his 'Other' skills.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat authentication methods has he implemented?\\n<|assistant|>\\nHe has experience with JWT (JSON Web Tokens) for REST APIs and Azure Identity Service for securing browser extensions.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhere is Sidharth located?\\n<|assistant|>\\nHe is located in Kerala, India.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat frameworks did he use for the Healthcare prototypes?\\n<|assistant|>\\nHe used AngularJS, Python, Django, Vue.js, and Flask.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nWhat was the impact of the Akamai report generator?\\n<|assistant|>\\nIt automated report generation, saving over 200 work hours annually at TCS.\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"<|user|>\\nDoes Sidharth do UI/UX design?\\n<|assistant|>\\nYes, he mentions modernizing UI/UX design for GRACE Sync, optimizing mobile experiences, and performing UI enhancements for Izycourse.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "dataset = Dataset.from_list(data)\n",
    "\n",
    "# 2. LOAD DEEPSEEK R1 DISTILL (1.5B)\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "# Quantization config (Makes the model smaller to fit in memory)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token # Fix for padding issues\n",
    "\n",
    "# 3. CONFIGURE TRAINING (LoRA)\n",
    "# This tells the system to only train a small \"adapter\" layer, not the whole massive model\n",
    "peft_config = LoraConfig(\n",
    "    r=16,       # Rank (complexity of the update matrices)\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# 4. START TRAINING\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\", # The column name in your data\n",
    "    max_seq_length=512,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate=2e-4,\n",
    "        logging_steps=1,\n",
    "        num_train_epochs=3, # Run over the data 3 times\n",
    "        fp16=True,\n",
    "    ),\n",
    "    peft_config=peft_config,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "\n",
    "# 5. SAVE THE NEW MODEL\n",
    "new_model_name = \"Sidharth-Portfolio-Bot\"\n",
    "trainer.model.save_pretrained(new_model_name)\n",
    "tokenizer.save_pretrained(new_model_name)\n",
    "print(f\"Model saved to {new_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f87fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "# Load the base model again\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Merge your trained \"adapter\" into the base model\n",
    "model = PeftModel.from_pretrained(base_model, \"Sidharth-Portfolio-Bot\")\n",
    "model = model.merge_and_unload() # Fuses the weights for faster speed\n",
    "\n",
    "# Inference Function\n",
    "def ask_bot(question):\n",
    "    prompt = f\"<|user|>\\n{question}\\n<|assistant|>\\n\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        **inputs, \n",
    "        max_new_tokens=50, \n",
    "        do_sample=True, \n",
    "        temperature=0.7\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Test it\n",
    "print(ask_bot(\"Who created this website?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
